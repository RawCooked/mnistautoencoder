# ğŸš€ Autoencoder for MNIST Digit Recognition

## ğŸ“Œ Overview
This project implements an **autoencoder** using **PyTorch** to reconstruct handwritten digits from the MNIST dataset. The model consists of an **encoder-decoder architecture** with convolutional layers, batch normalization, dropout, and fully connected layers to improve learning and generalization.

## âœ¨ Features
âœ… **Autoencoder Architecture:** Uses convolutional layers for feature extraction and transposed convolution for reconstruction.
âœ… **Data Preprocessing:** Normalizes pixel values to the range [0,1] and reshapes images to (1, 28, 28).
âœ… **GPU Support:** Automatically detects and utilizes GPU for training if available.
âœ… **Visualization:** Displays original and reconstructed images after training.

## âš™ï¸ Installation
### ğŸ“‹ Requirements
Ensure you have the following installed:
- ğŸ **Python 3.7+**
- ğŸ”¥ **PyTorch**
- ğŸ—ƒï¸ **pandas**
- ğŸ“Š **matplotlib**

### ğŸ› ï¸ Setup
Clone this repository and install dependencies:
```sh
$ git clone https://github.com/your-repo/autoencoder-mnist.git
$ cd autoencoder-mnist
$ pip install -r requirements.txt
```

## ğŸš€ Usage
### ğŸ‹ï¸ Training the Autoencoder
1. ğŸ“¥ Download the MNIST dataset from Kaggle.
2. âœï¸ Modify `file_path` in the script to point to the dataset.
3. â–¶ï¸ Run the script:
   ```sh
   python train_autoencoder.py
   ```

### ğŸ“¸ Visualizing Results
After training, reconstructed images will be displayed to evaluate the performance.

## ğŸ—ï¸ Model Architecture
### ğŸ”· Encoder
- ğŸ—ï¸ **Conv2d (1 -> 32) + ReLU + BatchNorm**
- ğŸ—ï¸ **Conv2d (32 -> 64) + ReLU + BatchNorm**
- ğŸ”„ **Flatten + Fully Connected (64*7*7 -> 128) + Dropout**

### ğŸ”¶ Decoder
- ğŸ”„ **Fully Connected (128 -> 64*7*7) + BatchNorm**
- ğŸ”„ **ConvTranspose2d (64 -> 32) + ReLU + BatchNorm**
- ğŸ”„ **ConvTranspose2d (32 -> 1) + Sigmoid**

## ğŸ“Š Results
The model progressively learns to reconstruct the MNIST digits, with the **Mean Squared Error loss decreasing** over **30 epochs** ğŸ“‰.

## ğŸ™Œ Acknowledgments
- ğŸ“œ MNIST dataset from **Kaggle**.
- ğŸ“š PyTorch documentation for deep learning implementation.

## ğŸ“œ License
This project is licensed under the **MIT License** ğŸ“„.

